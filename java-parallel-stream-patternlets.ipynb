{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkurniawati/java-parallel-stream-patternlets/blob/master/java-parallel-stream-patternlets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "# Java Parallel Stream Patternlet Notebook\n",
        "\n",
        "Adapted to Java parallel stream by Ruth Kurniawati (Westfield State University) based on the [PDC book](https://pdcbook.calvin.edu/pdcbook/RaspberryPiHandout/) from [CSInParallel](https://csinparallel.org/index.html). \n",
        "\n",
        "This notebook contains patternlet examples in Java parallel stream. Patterns are reusable solution for commonly occuring problems. The parallel design patternlets are minimalist patterns to teach parallel programming. The orignal patternlets were originally written in the C language for the OpenMP and MPI by Joel Adams: \n",
        "\n",
        "> Adams, Joel C. \"Patternlets: A Teaching Tool for Introducing Students to Parallel Design Patterns.\" 2015 IEEE International Parallel and Distributed Processing Symposium Workshop. IEEE, 2015.\n",
        "\n",
        "However, OpenMP and MPI are not available in Java. In this notebook, we will be using the higher level concurrency objects, specifically parallel streams. These objects are included in the Java Development Kit (JDK) starting from version 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MmtgBkPiZrw"
      },
      "source": [
        "# Multicore Systems and Multi-Threading\n",
        "\n",
        "Before proceeding with the examples, let's investigate the computer that this notebook is running on. For this, let's use the `lscpu` command. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khorTJcRlozK"
      },
      "outputs": [],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY1glALCX8qK"
      },
      "source": [
        "## Cores, Processes and Threads\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo98NtHglr9y"
      },
      "source": [
        "If you run `lscpu` in the notebook, you may see output similar to below:\n",
        "\n",
        "```\n",
        "Architecture:        x86_64\n",
        "CPU op-mode(s):      32-bit, 64-bit\n",
        "Byte Order:          Little Endian\n",
        "CPU(s):              2\n",
        "On-line CPU(s) list: 0,1\n",
        "Thread(s) per core:  2\n",
        "Core(s) per socket:  1\n",
        "Socket(s):           1\n",
        "NUMA node(s):        1\n",
        "Vendor ID:           GenuineIntel\n",
        "CPU family:          6\n",
        "Model:               79\n",
        "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
        "Stepping:            0\n",
        "CPU MHz:             2199.998\n",
        "BogoMIPS:            4399.99\n",
        "Hypervisor vendor:   KVM\n",
        "Virtualization type: full\n",
        "L1d cache:           32K\n",
        "L1i cache:           32K\n",
        "L2 cache:            256K\n",
        "L3 cache:            56320K\n",
        "NUMA node0 CPU(s):   0,1\n",
        "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
        "```\n",
        "\n",
        "This output means that the computer has 2 CPUs -- however, there is actually only one physical core but this core can execute 2 execution threads. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdhYtKRaYTBj"
      },
      "source": [
        "The `lscpu` command tells us a LOT of useful information, including the number of available cores. In this case we know that there is one socket (or chip) with 1 physical core, where each core can support 2 thread. On larger systems, it is common to see multiple threads supported per core. This is an example of **simultaneous multi-threading** (SMT, or Hyperthreading on Intel systems). A **core** can be thought of as the compute unit of the CPU. It includes registers, an ALU, and control units.\n",
        "\n",
        "Before we can discuss what a thread is, we must first discuss what a process is. A **process** can be thought of as an abstraction of a running program. When you type a command into the command line and press Enter, the Bash shell launches a process associated with that program executable. Each process contains a copy of the code and data of the program executable, and its own allocation of the stack and heap.\n",
        "\n",
        "A **thread** is a light-weight process. While each thread gets its own stack allocation, it shares the heap, code and data of the parent process. As a result, all the threads in a multi-threaded process can access a common pool of memory. This is why multi-threading is commonly referred to as shared memory programming. A single-threaded process is also referred to as a serial process or program."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BT6lHhc3Dv"
      },
      "source": [
        "### Process Execution\n",
        "A multicore CPU allows multiple processes to execute simultaneously, or in **parallel**. While the terms concurrency and parallel are related, it is useful to think of concurrency as a software/OS-level concept, while parallel as a hardware/execution concept. A multi-threaded program, while capable of parallel execution, runs concurrently on a system with only a single CPU core."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaLDQy2CdIB1"
      },
      "source": [
        "## Thread Execution\n",
        "\n",
        "The primary goal of creating multi-threaded programs is to decrease the speed of a program’s execution. In a program that is perfectly parallelizable (that is, all components are paralleizable), it is usually possible to distribute the work associated with a program equally among all the threads. For a program _p_ whose work is equally distributed among _t_ threads, it will take roughly _p_/_t_ time, if executed on _t_ cores.\n",
        "\n",
        "For example, if a multi-threaded process that is perfectly parallelized takes 100 seconds to execute on one core, on a multi-core system with 4 cores the program will take approximately 100/4 seconds = 25 seconds to execute."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iskUMiEdtbk"
      },
      "source": [
        "## Leveraging Multiple Cores\n",
        "While multicore processors are ubiquitous in today’s world, most of the popular programming languages were designed to support single-thread execution. However, several native libraries are available for supporting multi-threading in popular languages like C/C++ and FORTRAN.\n",
        "\n",
        "One of these libraries is the Open MultiProcessing (OpenMP), a popular API for shared memory programming, and a standard since 1997. A key benefit of OpenMP over explicit threading libraries like POSIX threads is the ability to incrementally add parallelism to a program. For standard threaded programs, it is usually necessary to write a lot of extra code to add multi-threading to a program. Instead, OpenMP employs a series of pragmas, or special compiler directives, that tell the compiler how to parallelize the code.\n",
        "\n",
        "OpenMP library is only available for C/C++ and Fortran languages. For Java, Pyjama compiler and runtime provide support for OpenMP-like directive. More information about Pyjama can be found in the paper below:\n",
        "\n",
        "Vikas, Nasser Giacaman, and Oliver Sinnen. 2013. Pyjama: OpenMP-like implementation for Java, with GUI extensions. In <i>Proceedings of the 2013 International Workshop on Programming Models and Applications for Multicores and Manycores</i> (<i>PMAM '13</i>). Association for Computing Machinery, New York, NY, USA, 43–52. DOI:https://doi.org/10.1145/2442992.2442997\n",
        "\n",
        "If you want to explore parallel programming using Pyjama in Java, please check out the Pyjama version of this notebook. \n",
        "\n",
        "In the rest of this notebook, we will use Java parallel stream to explore small patterns (_patternlets_) in parallel programming. \n",
        "\n",
        "A quick tutorial on Java parallel stream can be found [here](https://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHnm-q8fp7ta"
      },
      "source": [
        "# A Simple Parallel Program\n",
        "\n",
        "## The SPMD Patternlet\n",
        "\n",
        "\n",
        "A patternlet is a small program that succinctly illustrates common patterns in parallel programming. The first patternlet we will study is Single Program, Multiple Data (SPMD). Let’s start by examining Spmd2.java, a program that uses a parallel stream to make it easy to run a portion of the program on multiple threads. Note that the variables `id` and `numThreads` are shared among the threads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7xCZbDnqVAC"
      },
      "outputs": [],
      "source": [
        "%%writefile Spmd.java\n",
        "import java.util.concurrent.Executors;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "import java.util.concurrent.ThreadPoolExecutor;\n",
        "import java.util.concurrent.TimeUnit;\n",
        "import java.util.stream.IntStream;\n",
        "\n",
        "class Spmd {\n",
        "\n",
        "    private static String threadName;\n",
        "    private static int numThreads;\n",
        "\n",
        "    public static void main(String[] args) throws Exception {\n",
        "\n",
        "        // check and parse argument\n",
        "        if (args.length == 0) {\n",
        "            System.out.println(\"Usage Spmd numThreads.\");\n",
        "            System.out.println(\"Number of threads should be >= 1\");\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        numThreads = Integer.parseInt(args[0]);\n",
        "        if (numThreads < 1) {\n",
        "            System.out.println(\"Usage Spmd numThreads.\");\n",
        "            System.out.println(\"Number of threads should be >= 1\");\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        // launch the parallel stream using the custom pool\n",
        "        ForkJoinPool customPool = new ForkJoinPool(numThreads);\n",
        "        customPool.submit(() -> \n",
        "            IntStream.range(0, numThreads).parallel().forEach(i -> {\n",
        "                threadName = Thread.currentThread().getName();\n",
        "                Thread.yield();\n",
        "                String message = \"Hello from \" +  threadName + \" from a pool of \" + numThreads;\n",
        "                System.out.println(message);\n",
        "            })\n",
        "        ).get();\n",
        "\n",
        "        System.out.println(\"Done.\");\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blePwuMok2OP"
      },
      "source": [
        "The executeCode call caused the the block of code within the curly braces be run on separate threads. Prior to the line containing the call to executeCode, the program is run serially. Within the executeCode function a thread pool with the specified number of threads is started and each thread runs the same block of code in the curly braces. Each thread is assigned its own name and runs separate copies of the code between the curly braces. Afterwards when shutdown is called, we wait for all threads to terminate and the execution threads get combined back into a single-threaded process (known as joining). Conceptually, the process looks like the following."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Tpt04ZrOQ6"
      },
      "source": [
        "<img src=https://pdcbook.calvin.edu/pdcbook/RaspberryPiHandout/_images/ForkJoin_SPMD.png >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJr5ChxylkDw"
      },
      "source": [
        "## Running the Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMm8AUZssydy"
      },
      "source": [
        "Just like in the HelloWorld example, first we need to use compile the source code using <code>javac</code>. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBferIsmrIRC"
      },
      "outputs": [],
      "source": [
        "!javac Spmd.java"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc0C9Q-Lsrg6"
      },
      "source": [
        "Now, we're ready to run the Spmd program. Let's specify that you'd like to have 10 threads by supplying this number in the command line argument. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOLa2FNvrNjK"
      },
      "outputs": [],
      "source": [
        "!java Spmd 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ORBtUPclotz"
      },
      "source": [
        "Try running the program a few times with 10 threads (press the run button in the cell above). Observe the output. Occasionally something will be amiss. Do you notice it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1hj5AT8l4jg"
      },
      "source": [
        "## Race Conditions\n",
        "\n",
        "Watch this [video](\n",
        "https://d32ogoqmya1dw8.cloudfront.net/files/csinparallel/raceconditions_workshop.mov) to help you understand what's going on. Note that the video is made for the C++ version of the program, however the underlying issue is the same. \n",
        "\n",
        "The Spmd program has a race condition where there are more than one threads modifying a shared variable. Which shared variable(s) is/are causing the problem?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KexJJTwunv0T"
      },
      "source": [
        "## Fixing the code\n",
        "\n",
        "For this example, the race condition can be avoided by ensuring that each threads has its own copy of `id` and `numThreads` variables. Instead of declaring them as `private static` member variables in the class, we declare them as local variables inside the task executed in each parallel stream."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFBEy0tppsYa"
      },
      "outputs": [],
      "source": [
        "%%writefile Spmd2.java\n",
        "import java.util.concurrent.Executors;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "import java.util.concurrent.ThreadPoolExecutor;\n",
        "import java.util.concurrent.TimeUnit;\n",
        "import java.util.stream.IntStream;\n",
        "\n",
        "class Spmd2 {\n",
        "\n",
        "\n",
        "    public static void main(String[] args) throws Exception {\n",
        "\n",
        "        // check and parse argument\n",
        "        if (args.length == 0) {\n",
        "            System.out.println(\"Usage Spmd2 numThreads.\");\n",
        "            System.out.println(\"Number of threads should be >= 1\");\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        int poolNumThreads = Integer.parseInt(args[0]);\n",
        "        if (poolNumThreads < 1) {\n",
        "            System.out.println(\"Usage Spmd2 numThreads.\");\n",
        "            System.out.println(\"Number of threads should be >= 1\");\n",
        "            return;\n",
        "        }\n",
        "\n",
        "        // launch the parallel stream using the custom pool\n",
        "        ForkJoinPool customPool = new ForkJoinPool(poolNumThreads);\n",
        "        customPool.submit(() -> \n",
        "            IntStream.range(0, poolNumThreads).parallel().forEach(i -> {\n",
        "                String threadName = Thread.currentThread().getName();\n",
        "                int numThreads = customPool.getParallelism();\n",
        "                Thread.yield();\n",
        "                String message = \"Hello from \" +  threadName + \" from a pool of \" + numThreads;\n",
        "                System.out.println(message);\n",
        "            })\n",
        "        ).get();\n",
        "\n",
        "        System.out.println(\"Done.\");\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWHF-hfyp3S9"
      },
      "source": [
        "Let's compile and run this modified program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-pLKA_Hp6GP"
      },
      "outputs": [],
      "source": [
        "!javac Spmd2.java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnwWKH6hp87h"
      },
      "outputs": [],
      "source": [
        "!java Spmd2 10  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6-zqcZlqACB"
      },
      "source": [
        "Were you able to reproduce the race condition using the corrected program? Why should you also declare `numThreads` as a private variable?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-qDxBrjqVqA"
      },
      "source": [
        "# Running Loops in Parallel\n",
        "\n",
        "Next we will consider a program that has a loop in it. An iterative for loop is a remarkably common pattern in all programming, primarily used to perform a calculation N times, often over a set of data containing N elements, using each element in turn inside the for loop.\n",
        "\n",
        "If there are no dependencies between the iterations (i.e. the order of them is not important), then the code inside the loop can be split between forked threads. However, the programmer must first decide how to partition the work between the threads. Specifically, how many and which iterations of the loop will each thread complete on its own?\n",
        "\n",
        "The **data decomposition** pattern describes the way how work is distributed across multiple threads. This chapter presents two patternlets, parallelLoop-equalChunks and parallelLoop-chunksOf1, that describe two common data decomposition strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bpf2GVFqrFk"
      },
      "source": [
        "## Parallel Loop, Equal Chunks\n",
        "\n",
        "Let's do more experiment stream and see how the work is divided into equal chunks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UQ7T_Nlq5ZS"
      },
      "outputs": [],
      "source": [
        "%%writefile ParallelLoopEqualChunks.java\n",
        "import java.util.stream.IntStream;\n",
        "\n",
        "public class ParallelLoopEqualChunks {\n",
        "    static final int REPS = 16;\n",
        "    static int numReps = REPS;\n",
        "\n",
        "    public static void main(String[] args) throws Exception {\n",
        "\n",
        "        // check and parse argument\n",
        "        if (args.length >= 1) {\n",
        "            numReps = Integer.parseInt(args[0]);\n",
        "        }\n",
        "\n",
        "        IntStream.range(0, numReps)\n",
        "                .parallel()\n",
        "                .forEach(i -> System.out.println(\"Thread \" +\n",
        "                        Thread.currentThread().getName() + \" performed iteration \" + i));\n",
        "        System.out.println(\"Done.\");\n",
        "\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADAdiP5UrDXi"
      },
      "source": [
        "The `parallel()` call does the following:\n",
        "- Call the [SplitIterator](https://docs.oracle.com/javase/8/docs/api/java/util/Spliterator.html) class to split the streams into chunks\n",
        "- Assign each chunks to threads in the common thread pool for parallel execution\n",
        "- At the end of the scope of the parallel stream (before we reach the `System.out.println(\"Done.\"), the execution will wait until all the threads are done executing.\n",
        "\n",
        "As in our previous example, the code up to the call to `Stream.parallel()` is run serially. The code that is following the `parallel()` call is run in parallel, with a subset of iterations assigned to each thread. After the implicit join at the end of the parallel stream, the program once again is a single-threaded process that executes serially to completion.\n",
        "\n",
        "In the above program, REPS is set to 16. If the program is run with 2 threads, then each thread gets approximately half the number of iterations of the loop. If the program is run with 4 threads, each thread gets about 1/4th of the number of iterations (see illustration below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz0dEXBPrhCg"
      },
      "source": [
        "<img src=\"https://pdcbook.calvin.edu/pdcbook/RaspberryPiHandout/_images/ParallelFor_Chunks-4_threads-1.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUAmJL3KrmPh"
      },
      "source": [
        "## Try It Out\n",
        "\n",
        "Try compile and run the program using the following commands below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drSrg4qirvUz"
      },
      "outputs": [],
      "source": [
        "!javac ParallelLoopEqualChunks.java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TuG5KOUr07X"
      },
      "outputs": [],
      "source": [
        "!java ParallelLoopEqualChunks 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZifCPWfEr-Vl"
      },
      "source": [
        "Try running the program a few times with 4 threads. How does the work in the for loop get assigned to the threads?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Controlling the Number of Threads\n",
        "\n",
        "To control the number of threads in a parallel stream, you have to create a fork-join thread pool and assign the execution of the parallel thread to this custom pool. "
      ],
      "metadata": {
        "id": "s_ytVLCqQs9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ParallelLoopEqualChunksCustomPool.java\n",
        "import java.util.stream.IntStream;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "\n",
        "public class ParallelLoopEqualChunksCustomPool {\n",
        "    static final int REPS = 16;\n",
        "    static int numReps = REPS;\n",
        "\n",
        "    public static void main(String[] args) throws Exception {\n",
        "        if (args.length == 0) {\n",
        "            System.out.println(\"Usage ParallelLoopEqualChunks numberOfRepetitions numberOfThreads\");\n",
        "        }\n",
        "\n",
        "        // check and parse arguments\n",
        "        final int numReps = (args.length > 0) ? Integer.parseInt(args[0]) : 16;\n",
        "        final int numThreads = (args.length > 1) ? Integer.parseInt(args[0]) : Runtime.getRuntime().availableProcessors();\n",
        "        \n",
        "        System.out.println(\"Number of threads \" + numThreads);\n",
        "\n",
        "        ForkJoinPool customPool = new ForkJoinPool(numThreads);\n",
        "        customPool.submit(() -> \n",
        "            IntStream.range(0, numReps)\n",
        "                    .parallel()\n",
        "                    .forEach(i -> {\n",
        "                        System.out.println(\"Thread \" + Thread.currentThread().getName() + \" completed iteration \" + i);\n",
        "                    })\n",
        "        ).get();\n",
        "        System.out.println(\"Done.\");\n",
        "\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "Hat-qwBtQqfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it out:"
      ],
      "metadata": {
        "id": "TcqUQNeESvyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!javac ParallelLoopEqualChunksCustomPool.java"
      ],
      "metadata": {
        "id": "AyejrshaSsrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 16 iterations using 4 threads:"
      ],
      "metadata": {
        "id": "fq545i97S45h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!java ParallelLoopEqualChunksCustomPool 16 4"
      ],
      "metadata": {
        "id": "y_b14hTNSyMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run 16 iterations using 8 threads:"
      ],
      "metadata": {
        "id": "dWJEVlPNTOsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!java ParallelLoopEqualChunksCustomPool 16 8"
      ],
      "metadata": {
        "id": "cQYuzDN0TUTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rrR9m6esSun"
      },
      "source": [
        "### Unequal Iterrations\n",
        "\n",
        "Also try using a different number of threads. Pick a number so that the number iterations cannot be equally divided by the number of threads, such as 5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmcjcOXEsl8H"
      },
      "outputs": [],
      "source": [
        "!java ParallelLoopEqualChunksCustomPool 22 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWgqjv6HsuTZ"
      },
      "source": [
        "What happens to the extra iterations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmO_5IZxs1R5"
      },
      "source": [
        "This equal-chunk decomposition is especially useful in the following scenarios:\n",
        "- Each iteration of the loop takes the same amount of time to finish\n",
        "- The loop involves accesses to data in consecutive memory locations (e.g. an array), allowing the program to take advantage of spatial locality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kt0EBxruM4o"
      },
      "source": [
        "## Another way to do parallel loop \n",
        "\n",
        "At this point, you have seen how we can use Java ThreadPool and ForJoinPool to run tasks in parallel. Java allows for a higher abstraction using parallel stream. A SplitIterator for the stream will try to split the stream (and the work) equally among threads. By default, a parallel stream will use the common\n",
        "thread pool; however you can also choose to provide your own thread pool.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_i2SGSav46M"
      },
      "outputs": [],
      "source": [
        "%%writefile ParallelLoopEqualChunks.java\n",
        "import java.util.ArrayList;\n",
        "import java.util.List;\n",
        "import java.util.concurrent.Callable;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "\n",
        "/**\n",
        " * \n",
        " * To specify the number of thread in the ForkJoinPool, specify the \n",
        " * java.util.concurrent.ForkJoinPool.common.parallelism system property. \n",
        " * \n",
        " * For example:\n",
        " *\n",
        " *    java -Djava.util.concurrent.ForkJoinPool.common.parallelism=100 ParallelLoopEqualChunks\n",
        " */\n",
        "public class ParallelLoopEqualChunks {\n",
        "    static final int REPS = 16;\n",
        "\n",
        "    static class ChunkExecutor implements Callable<Void> {\n",
        "        private int startIndex, endIndex;\n",
        "\n",
        "        public ChunkExecutor(int startIndex, int endIndex) {\n",
        "            this.startIndex = startIndex;\n",
        "            this.endIndex = endIndex; // not inclusive\n",
        "        }\n",
        "\n",
        "        @Override\n",
        "        public Void call() throws Exception {\n",
        "            for(int i = startIndex; i < endIndex; i++) {\n",
        "                System.out.println(\"Thread \" + Thread.currentThread().getName() + \" performed iteration \" + i);\n",
        "            }\n",
        "            return null;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public static void main(String[] args) {\n",
        "        \n",
        "        // check and parse argument\n",
        "        int numReps = REPS;\n",
        "        if (args.length >= 1) {\n",
        "            numReps = Integer.parseInt(args[0]);\n",
        "        }\n",
        "\n",
        "        // initialize the thread pool\n",
        "        ForkJoinPool fjp = new ForkJoinPool();\n",
        "        int numThreads = fjp.getParallelism();\n",
        "        System.out.println(\"Number of repetitions \" + numReps);\n",
        "        System.out.println(\"Number of parallel threads \" + numThreads);\n",
        "\n",
        "        // divide the work\n",
        "        List<ChunkExecutor> tasks = new ArrayList<>();\n",
        "        int startIndex = 0;\n",
        "\n",
        "        for(int i = 0; i < numThreads; i++) {\n",
        "            int leftOver = (numReps % numThreads <= i) ? 0 : 1; \n",
        "            \n",
        "            // if REPS is not divisible evenly, spread it over threads\n",
        "            int chunkSize = numReps / numThreads + leftOver;\n",
        "\n",
        "            assert(startIndex+leftOver+chunkSize <= numReps);\n",
        "\n",
        "            tasks.add(new ChunkExecutor(startIndex, startIndex + chunkSize));\n",
        "            startIndex += chunkSize;\n",
        "        }\n",
        "\n",
        "        fjp.invokeAll(tasks);\n",
        "\n",
        "        System.out.println(\"Done.\");\n",
        "\n",
        "    }\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6oRwa8EwDob"
      },
      "outputs": [],
      "source": [
        "!javac ParallelLoopEqualChunks.java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFANxSybwIiY"
      },
      "outputs": [],
      "source": [
        "!java ParallelLoopEqualChunks 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfmlAD0ntBTy"
      },
      "source": [
        "## Parallel Loop, Chunks of 1\n",
        "\n",
        "In some cases, it makes sense to have iterations assigned to threads in “round-robin” style. In other words, iteration 0 goes to thread 0, iteration 1 goes to thread 1, iteration 2 goes to thread 2, and so on.\n",
        "\n",
        "Let's examine the code below that directs Pyjama to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92YGOmQOtStE"
      },
      "outputs": [],
      "source": [
        "%%writefile ParallelLoopChunksOf1.java\n",
        "import java.util.ArrayList;\n",
        "import java.util.List;\n",
        "import java.util.concurrent.Callable;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "\n",
        "/**\n",
        " * \n",
        " * To specify the number of thread in the ForkJoinPool, specify the java.util.concurrent.ForkJoinPool.common.parallelism system property. For example:\n",
        " *\n",
        " *    java -Djava.util.concurrent.ForkJoinPool.common.parallelism=100 ParallelLoopEqualChunks\n",
        " */\n",
        "public class ParallelLoopChunksOf1 {\n",
        "    static final int REPS = 16;\n",
        "\n",
        "    static class ChunkExecutor implements Callable<Void> {\n",
        "        private int startIndex, endIndex, step;\n",
        "\n",
        "        public ChunkExecutor(int startIndex, int endIndex, int step) {\n",
        "            this.startIndex = startIndex;\n",
        "            this.endIndex = endIndex; // not inclusive\n",
        "            this.step = step;\n",
        "        }\n",
        "\n",
        "        @Override\n",
        "        public Void call() throws Exception {\n",
        "            for(int i = startIndex; i < endIndex; i+=step) {\n",
        "                System.out.println(\"Thread \" + Thread.currentThread().getName() + \" performed iteration \" + i);\n",
        "            }\n",
        "            return null;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public static void main(String[] args) {\n",
        "        \n",
        "        // check and parse argument\n",
        "        int numReps = REPS;\n",
        "        if (args.length >= 1) {\n",
        "            numReps = Integer.parseInt(args[0]);\n",
        "        }\n",
        "\n",
        "        // initialize the thread pool\n",
        "        ForkJoinPool fjp = new ForkJoinPool();\n",
        "        int size = fjp.getParallelism();\n",
        "\n",
        "        // divide the work\n",
        "        List<ChunkExecutor> tasks = new ArrayList<>();\n",
        "        for(int i = 0; i < size; i++) {\n",
        "            tasks.add(new ChunkExecutor(i, numReps, size));\n",
        "        }\n",
        "\n",
        "        fjp.invokeAll(tasks);\n",
        "\n",
        "        System.out.println(\"Done.\");\n",
        "\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akcD6-Qqtfcn"
      },
      "source": [
        "The code is nearly identical to the previous program. The difference is in the `omp` directive. The `omp parallel for` directive has a new `schedule` clause which specifies the way iterations should be assigned to threads. The `static` keyword indicates that the the compiler should assign work to each thread at compile time (a **static** scheduling policy). The `1` indicates that the chunk size should be 1 iteration. Therefore, the above code would have 16 total chunks.\n",
        "\n",
        "In the case where the number of chunks exceed the number of theads, each successive chunk is assigned to a thread in round-robin fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tORVRFXutPEv"
      },
      "source": [
        "### Try It Out\n",
        "\n",
        "Let's compile and run the code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmBOb2wQt2BI"
      },
      "outputs": [],
      "source": [
        "!javac ParallelLoopChunksOf1.java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146eEyqOt7HR"
      },
      "outputs": [],
      "source": [
        "!java ParallelLoopChunksOf1 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPUwcDDkwAzy"
      },
      "source": [
        "Compare the work assignment in this program with the previous program that uses `#omp for` directive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V9l3PXwwYv0"
      },
      "source": [
        "## Dynamic Scheduling\n",
        "\n",
        "In some cases, it is beneficial for the assignment of loop iterations to occur at run-time. Both Java fork join thread pool and parallel stream will assign work to threads at runtime. The fork join thread pool thread will be assigned any available task in its queue and if needed it can steal work from another thread. \n",
        "\n",
        "An example of programs that will benefit from dynamic scheduling are shown below. The amount of work time the thread will sleep will be different and thread that has longer sleep time will require more \"work\" from the thread (occupying the thread for a longer time). \n",
        "\n",
        "Try experimenting with them and see how the tasks get assigned to different threads with changes in \"workload\" (sleep time). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6yVgZcWw3T-"
      },
      "outputs": [],
      "source": [
        "%%writefile DynamicSchedulingStream.java\n",
        "import java.util.stream.IntStream;\n",
        "\n",
        "public class DynamicSchedulingStream {\n",
        "    static final int REPS = 16;\n",
        "\n",
        "    static void sleepALittle(int numMillis) {\n",
        "        try { \n",
        "            Thread.sleep(numMillis); \n",
        "        } catch(InterruptedException e) {\n",
        "            // do nothing\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public static void main(String[] args) throws Exception {\n",
        "        int numReps = 16;\n",
        "        // check and parse argument\n",
        "        if (args.length >= 1) {\n",
        "            numReps = Integer.parseInt(args[0]);\n",
        "        }\n",
        "\n",
        "        IntStream.range(0, numReps)\n",
        "                .parallel()\n",
        "                .forEach(i -> {\n",
        "                    final int sleepTime = ((i % 6 == 0) ? 1000 : 1);\n",
        "                    System.out.println(\"Thread \" + Thread.currentThread().getName() + \" about to sleep \" + sleepTime + \" ms\");\n",
        "                    sleepALittle(sleepTime);\n",
        "                    System.out.println(\"Thread \" + Thread.currentThread().getName() + \" finished sleeping \" + sleepTime + \" ms\");\n",
        "                });\n",
        "        System.out.println(\"Done.\");\n",
        "\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITg5R2VjxkjE"
      },
      "outputs": [],
      "source": [
        "!javac DynamicSchedulingStream.java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUb8iLaGxnn8"
      },
      "outputs": [],
      "source": [
        "!java DynamicSchedulingStream 16 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below you will find another example of dynamic scheduling, but this time we utilize a ForkJoinPool."
      ],
      "metadata": {
        "id": "VqvFn0j8eVJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile DynamicSchedulingForkJoinPool.java\n",
        "import java.util.ArrayList;\n",
        "import java.util.List;\n",
        "import java.util.Random;\n",
        "import java.util.concurrent.Callable;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "\n",
        "public class DynamicSchedulingForkJoinPool {\n",
        "    static final int REPS = 16;\n",
        "\n",
        "    static void sleepALittle(int numMillis) {\n",
        "        try { \n",
        "            Thread.sleep(numMillis); \n",
        "        } catch(InterruptedException e) {\n",
        "            // do nothing\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public static void main(String[] args) {\n",
        "        \n",
        "        // check and parse argument\n",
        "        int numReps = REPS;\n",
        "        if (args.length >= 1) {\n",
        "            numReps = Integer.parseInt(args[0]);\n",
        "        }\n",
        "\n",
        "        // initialize the thread pool\n",
        "        ForkJoinPool fjp = new ForkJoinPool();\n",
        "        int numThreads = fjp.getParallelism();\n",
        "        System.out.println(\"Number of repetitions \" + numReps);\n",
        "        System.out.println(\"Number of parallel threads \" + numThreads);\n",
        "\n",
        "        Random r = new Random();\n",
        "        List<Callable<Void>> tasks = new ArrayList<>();\n",
        "        for(int i = 0; i < numReps; i++) {\n",
        "            final int sleepTime = ((i % 6 == 0) ? 1000 : 1);\n",
        "\n",
        "            tasks.add(() -> {\n",
        "                System.out.println(\"Thread \" + Thread.currentThread().getName() + \" about to sleep \" + sleepTime + \" ms\");\n",
        "                sleepALittle(sleepTime);\n",
        "                System.out.println(\"Thread \" + Thread.currentThread().getName() + \" finished sleeping \" + sleepTime + \" ms\");\n",
        "                return null;\n",
        "            });\n",
        "        }\n",
        "\n",
        "        fjp.invokeAll(tasks);\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "XJurceiQ1yvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!javac DynamicSchedulingForkJoinPool.java"
      ],
      "metadata": {
        "id": "Ez0KPFiG17ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java DynamicSchedulingForkJoinPool"
      ],
      "metadata": {
        "id": "oiD7_Zqre1kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugMwRIBFn0cJ"
      },
      "source": [
        "# Parallel Sum\n",
        "\n",
        "Very often, loops are used with an accumulator variable to compute a a single value from a set of values, such as the sum of integers in an array or list. Fortunately, Java stream provides a *reduce* method, an implementation of the [*reduction*](https://docs.oracle.com/javase/tutorial/collections/streams/reduction.html) operation, which will aid us in this process. The reduction pattern is one of a group of patterns called **collective communication** patterns because the threads must somehow work together to create the final desired single value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhyoHP-VoGX6"
      },
      "source": [
        "## Initial Attempt\n",
        "\n",
        "Let's try implementing parallel sum without using the _reduce_ method. \n",
        "\n",
        "The `Reduction0` program below will create an array with 1 million integers that are generated randomly in the [0-1000) range. Note that `sequentialSum` sums up the array sequentially. The code in `parallelSum` uses OpenMP's parallel and for directives to attempt to sum up the array in parallel. Examine the two functions carefully. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCHUZ8b3onCq"
      },
      "outputs": [],
      "source": [
        "%%writefile ReductionRace.java\n",
        "import java.util.List;\n",
        "import java.util.Random;\n",
        "import java.util.concurrent.ExecutionException;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "import java.util.stream.Collectors;\n",
        "\n",
        "public class ReductionRace {\n",
        "    private static final long SIZE = 1_000_000;\n",
        "    private static final int MAX = 1_000;\n",
        "\n",
        "    // the total in sequential and parallel\n",
        "    private static int seqTotal, parTotal1, parTotal2;\n",
        "\n",
        "    static void sequentialSum(List<Integer> randomInts) {\n",
        "        randomInts.stream().forEach(i->seqTotal = seqTotal+i);\n",
        "    }\n",
        "\n",
        "    // parallel sum using a common pool\n",
        "    static void parallelSum1(List<Integer> randomInts) {\n",
        "        randomInts.parallelStream().forEach(\n",
        "            i-> parTotal1= parTotal1 + i\n",
        "        );\n",
        "    }\n",
        "\n",
        "    // parallel sum using a custom pool\n",
        "    static void parallelSum2(List<Integer> randomInts, ForkJoinPool customThreadPool) {\n",
        "        try {\n",
        "            customThreadPool.submit(\n",
        "                () ->{\n",
        "                    randomInts.parallelStream().forEach(i->parTotal2 = parTotal2 + i); \n",
        "                    return null;\n",
        "                }).get();\n",
        "        } catch (InterruptedException e) {\n",
        "            e.printStackTrace();\n",
        "        } catch (ExecutionException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    public static void main(String[] args) {\n",
        "        // generate a stream of random integer in [0..MAX)\n",
        "        List<Integer> randomInts = (new Random(123)).ints(0, MAX).limit(SIZE)\n",
        "                .mapToObj(x -> x).collect(Collectors.toList());\n",
        "\n",
        "        // sequential \n",
        "        long startTime = System.currentTimeMillis();\n",
        "        sequentialSum(randomInts);\n",
        "        long seqTime = System.currentTimeMillis() - startTime;\n",
        "        System.out.println(\"Seq total \" + seqTotal + \", calculated in \" + seqTime + \" ms.\");\n",
        "\n",
        "        // using common pool\n",
        "        startTime = System.currentTimeMillis();\n",
        "        parallelSum1(randomInts);\n",
        "        long parTime1 = System.currentTimeMillis() - startTime;\n",
        "        System.out.println(\"Parallel total \" + parTotal1 + \", calculated in \" + parTime1 + \" ms.\");\n",
        "\n",
        "        // use custom pool\n",
        "        ForkJoinPool customThreadPool = new ForkJoinPool(Runtime.getRuntime().availableProcessors());\n",
        "        startTime = System.currentTimeMillis();\n",
        "        parallelSum2(randomInts, customThreadPool);\n",
        "        long parTime2 = System.currentTimeMillis() - startTime;\n",
        "        System.out.println(\"Parallel total \" + parTotal2 + \", calculated in \" + parTime2 + \" ms.\");\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHZYNCp1o8Bo"
      },
      "outputs": [],
      "source": [
        "!javac ReductionRace.java"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java ReductionRace"
      ],
      "metadata": {
        "id": "b06CtBpOgZVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oo9BtilpPRs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oHILB5LW7m6"
      },
      "source": [
        "Note that the sum from the sequentialSum is different from the sum from the parallelSum. Try running the program multiple times. \n",
        "\n",
        "Note that the set of random numbers generated are the same each time you run the program since we supplied the seed for the random number generator to be `123`.  \n",
        "\n",
        "Are the results of the `sequentialSum` function changing? How about the results of the `parallelSum` function? Can you explain why the results of sequential and parallel sum are different?\n",
        "\n",
        "How many threads were used to calculate the sum in `parallelSum`? What happens when you change this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcYipzXeX951"
      },
      "source": [
        "## Fixing the parallelSum function\n",
        "\n",
        "Let's try a different version of the parallelSum function (below). Note that this version use the _reduce_ method. \n",
        "\n",
        "The notion of a reduction comes from the mathematical operation _reduce_, in which a collection of values are combined into a single value via a common mathematical function. Summing up a collection of values is a natural example of reduction. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S72_dEZBZtC0"
      },
      "outputs": [],
      "source": [
        "%%writefile Reduction.java\n",
        "import java.util.List;\n",
        "import java.util.Random;\n",
        "import java.util.concurrent.ExecutionException;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "import java.util.stream.Collectors;\n",
        "\n",
        "public class Reduction {\n",
        "    private static final long SIZE = 1_000_000;\n",
        "    private static final int MAX = 1_000;\n",
        "\n",
        "    static int sequentialSum(List<Integer> randomInts) {\n",
        "        return randomInts.stream().reduce(0, Integer::sum);\n",
        "    }\n",
        "\n",
        "    // parallel sum using a common pool\n",
        "    static int parallelSum1(List<Integer> randomInts) {\n",
        "        return randomInts.parallelStream().reduce(0, Integer::sum);\n",
        "    }\n",
        "\n",
        "    // parallel sum using a custom pool\n",
        "    static int parallelSum2(List<Integer> randomInts, ForkJoinPool customThreadPool) {\n",
        "        try {\n",
        "            return customThreadPool.submit(\n",
        "                        () -> randomInts.parallelStream().reduce(0, Integer::sum)\n",
        "                    ).get();\n",
        "        } catch (InterruptedException e) {\n",
        "            e.printStackTrace();\n",
        "        } catch (ExecutionException e) {\n",
        "            e.printStackTrace();\n",
        "        }\n",
        "        return 0;\n",
        "    }\n",
        "    \n",
        "    public static void main(String[] args) {\n",
        "        // generate a stream of random integer in [0..MAX)\n",
        "        List<Integer> randomInts = (new Random(123)).ints(0, MAX).limit(SIZE)\n",
        "                .mapToObj(x -> x).collect(Collectors.toList());\n",
        "\n",
        "        // sequential \n",
        "        long startTime = System.currentTimeMillis();\n",
        "        int seqTotal = sequentialSum(randomInts);\n",
        "        long seqTime = System.currentTimeMillis() - startTime;\n",
        "        System.out.println(\"Seq total \" + seqTotal + \", calculated in \" + seqTime + \" ms.\");\n",
        "\n",
        "        // using common pool\n",
        "        startTime = System.currentTimeMillis();\n",
        "        int parTotal1 = parallelSum1(randomInts);\n",
        "        long parTime1 = System.currentTimeMillis() - startTime;\n",
        "        System.out.println(\"Parallel total \" + parTotal1 + \", calculated in \" + parTime1 + \" ms.\");\n",
        "\n",
        "        // use custom pool\n",
        "        ForkJoinPool customThreadPool = new ForkJoinPool(Runtime.getRuntime().availableProcessors());\n",
        "        startTime = System.currentTimeMillis();\n",
        "        int parTotal2 = parallelSum2(randomInts, customThreadPool);\n",
        "        long parTime2 = System.currentTimeMillis() - startTime;\n",
        "\n",
        "        System.out.println(\"Parallel total \" + parTotal2 + \", calculated in \" + parTime2 + \" ms.\");\n",
        "    }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChlUru_CZ6Zd"
      },
      "outputs": [],
      "source": [
        "!javac Reduction.java"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java Reduction"
      ],
      "metadata": {
        "id": "GID_6ME3ggum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qC_bn88cgPH"
      },
      "source": [
        "Try running the program a few times and compare the results of `sequentialSum` and `parallelSum` again. Are they the same? \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXhleGldc-J0"
      },
      "source": [
        "## Something to ponder\n",
        "\n",
        "What do you think happen when you specify the `reduce` function? \n",
        "\n",
        "Can you fix `parallelSum1` and `parallelSum2` functions so that they will produce the correct result without using the `reduce` clause?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4rSf3wbdax-"
      },
      "source": [
        "The sum example that we experimented with was a fairly small example. We will look at larger examples in the following sections. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uvQmDyvdl0V"
      },
      "source": [
        "# Integration using the Trapezoidal Rule\n",
        "\n",
        "## Estimating the Area Under a Curve\n",
        "\n",
        "As our next example, let’s look at the problem of estimating the area under a curve. If you have taken a calculus course, you may recognize this problem as the Riemann sum or Trapezoidal Rule, which approximates the area under the curve (i.e. the integral) by splitting the area under the curve into a series of trapezoids.\n",
        "\n",
        "In the following programs, we attempt to use the trapezoid rule to approximate the integral:\n",
        "\n",
        "  $\\int_0^{\\pi} sin(x)_{dx}$\n",
        "\n",
        "using $2^{20}$ equal subdivisions. The answer from this computation should be 2.0. This [video](https://d32ogoqmya1dw8.cloudfront.net/files/csinparallel/workshops/numerical_integration_1_thread.mov) shows how a single thread would solve this problem. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1VAUgOafVbo"
      },
      "source": [
        "In the following program, a single thread serially computes the area of each trapezoid and adds all the trapezoids together into one value. A Java implementation of this program may look like the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uqF6TD9fUgS"
      },
      "outputs": [],
      "source": [
        "%%writefile Integration.java\n",
        "import java.util.stream.IntStream;\n",
        "import java.util.List;\n",
        "import java.util.function.DoubleBinaryOperator;\n",
        "import java.util.stream.Collectors;\n",
        "\n",
        "class Integration {\n",
        "    static double integral; // variable to accumulate answer\n",
        "\n",
        "    static double f(double x) {\n",
        "        return Math.sin(x);\n",
        "    }\n",
        "    \n",
        "    public static void main(String[] args) {\n",
        "        //Variables\n",
        "\n",
        "        final double a = 0.0, b = Math.PI;         //limits of integration\n",
        "        int n = 1048576;                           //number of subdivisions = 2^20\n",
        "        final double h = (b - a) / n;              //width of each subdivision\n",
        "\n",
        "        //sum up all the trapezoids\n",
        "        List<Integer> indexes = IntStream.range(0, n+1).mapToObj(i->i)\n",
        "            .collect(Collectors.toList());\n",
        "        indexes.stream().forEach(i -> integral += f(a+i*h));;\n",
        "\n",
        "        integral = integral * h;\n",
        "        System.out.printf(\"With %d trapezoids, our estimate of the integral from \\n\", n);\n",
        "        System.out.printf(\"%f to %f is %f\\n\", a,b,integral);\n",
        "    } \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg_ZBNE2tvLI"
      },
      "source": [
        "Let's compile and run this as a normal Java program:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQGUeDZrtnRk"
      },
      "outputs": [],
      "source": [
        "!javac Integration.java"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java Integration"
      ],
      "metadata": {
        "id": "lzjbWLBogl7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byn7aKFXuEBq"
      },
      "source": [
        "## Parallel Integration - First Attempt\n",
        "\n",
        "Let’s now consider how we can use multiple threads to approximate the area under the curve in parallel. One strategy would be to assign each thread a subset of the total set of subdivisions, so that each thread separately computes its assigned set of trapezoids.\n",
        "\n",
        "This [video](https://d32ogoqmya1dw8.cloudfront.net/files/csinparallel/workshops/numerical_integration_4_threads.mov) illustrates how 4 threads would work together to approximate the area under the curve.\n",
        "\n",
        "Here's an attempt to parallelize the serial version above using a parallel stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwl56w-dwYvq"
      },
      "outputs": [],
      "source": [
        "%%writefile Integration1.java\n",
        "import java.util.stream.IntStream;\n",
        "import java.util.List;\n",
        "import java.util.function.DoubleBinaryOperator;\n",
        "import java.util.stream.Collectors;\n",
        "\n",
        "class Integration1 {\n",
        "    static double integral; // variable to accumulate answer\n",
        "\n",
        "    static double f(double x) {\n",
        "        return Math.sin(x);\n",
        "    }\n",
        "    \n",
        "    public static void main(String[] args) {\n",
        "        //Variables\n",
        "\n",
        "        final double a = 0.0, b = Math.PI;         //limits of integration\n",
        "        int n = 1048576;                           //number of subdivisions = 2^20\n",
        "        final double h = (b - a) / n;              //width of each subdivision\n",
        "\n",
        "        //sum up all the trapezoids\n",
        "        List<Integer> indexes = IntStream.range(0, n+1).mapToObj(i->i)\n",
        "            .collect(Collectors.toList());\n",
        "        indexes.parallelStream().forEach(i -> integral += f(a+i*h));;\n",
        "\n",
        "        integral = integral * h;\n",
        "        System.out.printf(\"With %d trapezoids, our estimate of the integral from \\n\", n);\n",
        "        System.out.printf(\"%f to %f is %f\\n\", a,b,integral);\n",
        "    } \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_QsY2hFwj07"
      },
      "outputs": [],
      "source": [
        "!javac Integration1.java"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java Integration"
      ],
      "metadata": {
        "id": "tJRh5Dc_g3L1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqqGo_jDwuxE"
      },
      "source": [
        "If our parallel program is implemented correctly, the program should estimate the area under the curve as 2.00, which would be identical to the output of the serial program.\n",
        "\n",
        "Below is the same program that uses a custom thread pool to allow you to specify the number of threads. Try running the program with different number of threads: 4, 2, 1. When will it produce the correct/expected value (2.0)?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Integration1CustomPool.java\n",
        "import java.util.stream.IntStream;\n",
        "import java.util.List;\n",
        "import java.util.function.DoubleBinaryOperator;\n",
        "import java.util.stream.Collectors;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "\n",
        "class Integration1CustomPool {\n",
        "    static double integral; // variable to accumulate answer\n",
        "\n",
        "    static double f(double x) {\n",
        "        return Math.sin(x);\n",
        "    }\n",
        "    \n",
        "    public static void main(String[] args) throws Exception {\n",
        "        int numThreads = Runtime.getRuntime().availableProcessors();\n",
        "        if (args.length >= 1) {\n",
        "            numThreads = Integer.parseInt(args[0]);\n",
        "            if (numThreads < 1) {\n",
        "                System.out.println(\"Usage \" + Integration1CustomPool.class.getName() + \" numThreads.\");\n",
        "                System.out.println(\"Number of threads should be >= 1\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "        System.out.println(\"Number of threads \" + numThreads);\n",
        "\n",
        "        //Variables\n",
        "\n",
        "        final double a = 0.0, b = Math.PI;         //limits of integration\n",
        "        int n = 1048576;                           //number of subdivisions = 2^20\n",
        "        final double h = (b - a) / n;              //width of each subdivision\n",
        "\n",
        "        //sum up all the trapezoids\n",
        "        ForkJoinPool customThreadPool = new ForkJoinPool(numThreads);\n",
        "\n",
        "        List<Integer> indexes = IntStream.range(0, n+1).mapToObj(i->i)\n",
        "            .collect(Collectors.toList());\n",
        "        customThreadPool.submit(\n",
        "            () -> indexes.parallelStream().forEach(i -> integral += f(a+i*h))\n",
        "        ).get();\n",
        "\n",
        "        integral = integral * h;\n",
        "        System.out.printf(\"With %d trapezoids, our estimate of the integral from \\n\", n);\n",
        "        System.out.printf(\"%f to %f is %f\\n\", a,b,integral);\n",
        "    } \n",
        "}"
      ],
      "metadata": {
        "id": "MnDxNt79Tn-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!javac Integration1CustomPool.java"
      ],
      "metadata": {
        "id": "dZZtYlAlUkwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnycCBXcwoSD"
      },
      "outputs": [],
      "source": [
        "!java Integration1CustomPool 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry-kHQ-w74-H"
      },
      "outputs": [],
      "source": [
        "!java Integration1CustomPool 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TlOAnn48TmpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSedoOBP752m"
      },
      "outputs": [],
      "source": [
        "!java Integration1CustomPool 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLDMVd_Y8AH5"
      },
      "source": [
        "## Parallel Integration - Second Attempt\n",
        "\n",
        "Now, let's use the previously discussed `reduction` function to fix the issue that we observed in previous section. Here's the improved version below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcmjxgXF8P50"
      },
      "outputs": [],
      "source": [
        "%%writefile Integration2.java\n",
        "import java.util.stream.Collectors;\n",
        "import java.util.stream.IntStream;\n",
        "import java.util.List;\n",
        "import java.util.function.DoubleBinaryOperator;\n",
        "\n",
        "class Integration2 {\n",
        "    static double f(double x) {\n",
        "        return Math.sin(x);\n",
        "    }\n",
        "    \n",
        "    public static void main(String[] args) {\n",
        "        //Variables\n",
        "\n",
        "        final double a = 0.0, b = Math.PI;         //limits of integration\n",
        "        int n = 1048576;                //number of subdivisions = 2^20\n",
        "        final double h = (b - a) / n;         //width of each subdivision\n",
        "\n",
        "        //sum up all the trapezoids\n",
        "        List<Integer> indexes = IntStream.range(0, n+1).mapToObj(i->i)\n",
        "            .collect(Collectors.toList());\n",
        "        double integral = indexes.parallelStream().mapToDouble(i -> f(a+i*h))\n",
        "           .reduce(0.0, Double::sum);\n",
        "\n",
        "        integral = integral * h;\n",
        "        System.out.printf(\"With %d trapezoids, our estimate of the integral from \\n\", n);\n",
        "        System.out.printf(\"%f to %f is %f\\n\", a,b,integral);\n",
        "    } \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOL2MR-C8Z1u"
      },
      "source": [
        "As with the previous reduction patternlet example, we again have an accumulator variable in the loop, this time called integral. Thus our reduction clause reads reduction(+:integral).\n",
        "\n",
        "Compile and run the above program with multiple threads using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPKl9LmI8jVg"
      },
      "outputs": [],
      "source": [
        "!javac Integration2.java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b026TnL384Wa"
      },
      "outputs": [],
      "source": [
        "!java Integration2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeqhURuY89Hu"
      },
      "source": [
        "Did you get the expected result? (2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11dm9-Mu9AS9"
      },
      "source": [
        "**Note**: \n",
        "\n",
        "Because we did not explicitly add an additional static or dynamic clause to the pragma on line 24 on the working version above, the default behavior of assigning equal amounts of work doing consecutive iterations of the loop (i.e. static scheduling) was used to decompose the problem onto threads. In this case, since the number of trapezoids used was 1048576, then with 4 threads, thread 0 will do the first 1048576/4 trapezoids, thread 1 the next 1048576/4 trapezoids, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3_pa6sD9VdX"
      },
      "source": [
        "# Performance Study - Drug Design Exemplar\n",
        "\n",
        "Let’s look at a larger example. An important problem in Biology is that of drug design. The goal is to find small molecules, called _ligands_, that are good candidates for use as drugs.\n",
        "\n",
        "This is a very rough simulation of a program to compute how well a set of short protein ligands (each a possible drug) matches a given longer protein string. In the real software programs that do this, the matching is quite sophisticated, targeting possible \"receptor\" sites on the protein.\n",
        "\n",
        "Here is an image illustrating the concept of the ligand (represented by small sticks in center) binding to areas of the protein (represented by ribbon structure):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy4urTvV9cBt"
      },
      "source": [
        "<img src=\"https://pdcbook.calvin.edu/pdcbook/RaspberryPiHandout/_images/proteinligand.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yk1d0Ki9k0U"
      },
      "source": [
        "For the real versions of this code and our simulated case, the longer the ligand or the longer the protein, the longer it takes for the matching and score of the match to complete.\n",
        "\n",
        "We have created a default fake protein in the code. This can be changed on the command line.\n",
        "\n",
        "We create the list of possible ligands by choosing random lengths (controlled by the `maxligand` variable). Thus, each ligand can be of a different length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h9xZ0tn94u4"
      },
      "source": [
        "## The Drug Design Exemplar\n",
        "\n",
        "Unlike previous code examples, this example is a larger program where you can practice measuring the performance improvement of a parallel program.\n",
        "\n",
        "An implementation of the exemplar is below. Try changing the number of threads and measure the speed-up. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vob8rA-Oz41M"
      },
      "outputs": [],
      "source": [
        "%%writefile DDStream.java\n",
        "import java.util.Random;\n",
        "import java.util.stream.IntStream;\n",
        "import java.util.concurrent.ForkJoinPool;\n",
        "\n",
        "public class DDStream {\n",
        "    static Random rand = new Random(42);\n",
        "\n",
        "    static String[] cannedLigands = \n",
        "        {\"razvex\", \"qudgy\", \"afrs\", \"sst\", \"pgfht\", \"rt\", \n",
        "        \"id\", \"how\", \"aaddh\",  \"df\", \"os\", \"hid\", \n",
        "        \"sad\", \"fl\", \"rd\", \"edp\", \"dfgt\", \"spa\"};\n",
        "\n",
        "    // Ligand Score pair\n",
        "    static class LSPair {\n",
        "        String ligand;\n",
        "        int score;\n",
        "    \n",
        "        public LSPair(String ligand, int score) {\n",
        "            this.ligand = ligand;\n",
        "            this.score = score;\n",
        "        }\n",
        "\n",
        "        @Override\n",
        "        public String toString() {\n",
        "            return \"[\"+ligand+\",\"+score+\"]\";\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // returns arbitrary string of lower-case letters of length at most max_ligand\n",
        "    static String makeLigand(int maxLigandLength) {\n",
        "\n",
        "        int len = rand.nextInt(maxLigandLength+1);\n",
        "        if (len == 0) len++; // don't create a 0-character ligand\n",
        "                \n",
        "        StringBuilder sb = new StringBuilder();\n",
        "        for (int i = 0;  i < len;  i++) \n",
        "            sb.append((char) ('a' + rand.nextInt(26)));  \n",
        "        return sb.toString();\n",
        "    }\n",
        "  \n",
        "    private static String[] generateLigands(int numLigands, int maxLigandLength, boolean useCanned) {\n",
        "        // If we use canned ligands, use as many of them as we can, then fill the rest with randomly generated ligands. \n",
        "        // Otherwise, create a set of ligands whose length randomly varies from 1 to args.maxLigand\n",
        "\n",
        "        String[] result = new String[numLigands];\n",
        "\n",
        "        if (useCanned) {\n",
        "            for(int i = 0; i < Math.min(numLigands, cannedLigands.length); i++) {\n",
        "                result[i] = cannedLigands[i];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for(int i = useCanned ? cannedLigands.length : 0; i < numLigands; i++) {\n",
        "            result[i] = makeLigand(maxLigandLength);\n",
        "        }\n",
        "        return result;\n",
        "    }\n",
        "\n",
        "    public static void main(String[] args) throws Exception {\n",
        "\n",
        "        if (args.length != 4) {\n",
        "            System.out.println(\"Usage DDStream numThreads numLigands maxLigandLength protein useCanned printLigands\");\n",
        "\n",
        "            // the example string below is one of Dijkstra's famous quotes\n",
        "            System.out.println(\"   Example: java -cp .:Pyjama.jar DDStream 4 10 8 \\\"Simplicity is a great virtue but it requires hard work to achieve it and education to appreciate it\\\" false true\\n\");\n",
        "        }\n",
        "\n",
        "        int numThreads = 4;\n",
        "        if (args.length >= 1) {\n",
        "            numThreads = Integer.parseInt(args[0]);\n",
        "        }\n",
        "\n",
        "        final int numLigands = (args.length >= 2) ? Integer.parseInt(args[1]) : 12;\n",
        "\n",
        "        int maxLigandLength = 6;\n",
        "        if (args.length >= 3) {\n",
        "            maxLigandLength = Integer.parseInt(args[2]);\n",
        "        }\n",
        "\n",
        "        final String protein = (args.length >= 4) ? \n",
        "            args[3] :\"the cat in the hat wore the hat to the cat hat party\";\n",
        "\n",
        "        System.out.println(\"Number of threads: \" + numThreads);\n",
        "        System.out.println(\"Number of ligands: \"+numLigands);\n",
        "        System.out.println(\"Max ligand length: \"+ maxLigandLength);\n",
        "        System.out.println(\"Protein: \"+ protein);\n",
        "        System.out.println();\n",
        "\n",
        "        // Things to do: \n",
        "        // 1. Generate the requested numLigands w/ maxLigandLength\n",
        "        // 2. Calculate the matching score for each ligand vs the given protein\n",
        "        //    Score is calculated based on the number of character in the ligand that\n",
        "        //    appears in the same order in the protein. \n",
        "        // 3. Find the ligand(s) with the highest score\n",
        "\n",
        "        long start = System.currentTimeMillis();\n",
        "        String[] ligands = generateLigands(numLigands, maxLigandLength, args.length >= 5 && args[4].equals(\"true\"));\n",
        "\n",
        "        // print the ligands if desired\n",
        "        if (args.length >= 6 && args[5].equals(\"true\")) {\n",
        "            System.out.println(\"Here are the ligands\");\n",
        "            for(String l : ligands) {\n",
        "                System.out.println(l);\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        // map each ligand to (ligand, score)\n",
        "        // also keep track of the maxScore \n",
        "        LSPair[] ligandsWScore = new LSPair[numLigands];\n",
        "\n",
        "        ForkJoinPool customThreadPool = new ForkJoinPool(numThreads);\n",
        "\n",
        "        int maxScore = customThreadPool.submit(\n",
        "            () -> IntStream.range(0, numLigands).parallel().map(\n",
        "                i -> {\n",
        "                    String ligand = ligands[i];\n",
        "                    int score = calcScore(ligand, protein);\n",
        "                    ligandsWScore[i] = new LSPair(ligand, score);\n",
        "                    return score;\n",
        "                }\n",
        "            ).reduce(Math::max)\n",
        "        ).get().getAsInt();\n",
        "\n",
        "        // find the ligands whose score is maxScore\n",
        "        // this is a reduce operation\n",
        "        StringBuilder sb = new StringBuilder();\n",
        "        for(int i = 0; i < numLigands; i++) {\n",
        "            if (ligandsWScore[i].score == maxScore) {\n",
        "                if (sb.length() > 0) sb.append(\", \");\n",
        "                sb.append(ligandsWScore[i].ligand);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        long end = System.currentTimeMillis();\n",
        "        System.out.println(\"The maximum score is \" + maxScore);\n",
        "        System.out.println(\"Achieved by ligand(s) \"+ sb.toString());\n",
        "        System.out.println(\"Calculation time \" + (end-start) + \" ms\");\n",
        "    }\n",
        "\n",
        "    /**\n",
        "     * Match a ligand (str1) and the protein. Count the number of characters in str1\n",
        "     * that appear in the same seq in str2 (there can be any number of intervening chars)\n",
        "     * @param str1 first string\n",
        "     * @param str2 second string\n",
        "     * @return number of matches\n",
        "     */\n",
        "    private static int calcScore(String str1, String str2) {\n",
        "        // no match if either is empty string\n",
        "        if (str1.length() == 0 || str2.length() == 0) return 0;\n",
        "\n",
        "        if (str1.charAt(0) == str2.charAt(0)) {\n",
        "            return 1 + calcScore(str1.substring(1), str2.substring(1));\n",
        "        }\n",
        "        return Math.max(\n",
        "            calcScore(str1, str2.substring(1)), calcScore(str1.substring(1), str2));\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heHlvVVdz-4h"
      },
      "outputs": [],
      "source": [
        "!javac DDStream.java"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java DDStream"
      ],
      "metadata": {
        "id": "XrQaM02uhFBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oic9JmgM34Hp"
      },
      "source": [
        "Try running it with more ligands and longer ligands length. Observe how much longer it takes for the program to finish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpCnmmRU4jgD"
      },
      "outputs": [],
      "source": [
        "!java DDStream 4 20 6 \"your time is limited, so don't waste it living someone else's life\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSVDY776kxR"
      },
      "source": [
        "## Speedup\n",
        "\n",
        "**Speedup** is the ratio of the execution time of a serial program to its parallel execution. Specifically,\n",
        "\n",
        "  $S_n= \\frac{T_1}{T_n}$\n",
        "\n",
        "Where $T_1$ is the time it takes to execute a program on 1 thread, while $T_n$ is the time it takes to execute a program on n threads. Some important notes:\n",
        "\n",
        " - A speedup greater than 1 indicates that there is benefit to the parallel implementation. A speedup of x means that the parallel code is x times faster.\n",
        " - A speedup less than 1 indicates that there is no benefit to parallelism.\n",
        "\n",
        "To correctly calculate speedup, we must first measure the running time of a program. In this case, we will use `System.currentTimeMillis` to measure how long it takes for the program to finish, starting from the ligand generation step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZoo1ytW73Sk"
      },
      "source": [
        "## Performance study\n",
        "\n",
        " Try running the program using different number of threads and different scheduling strategy and complete the table below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsUPVw_U8o3p"
      },
      "source": [
        "|         | 1 Thread | 2 Threads | 3 Threads | 4 Threads |\n",
        "|---------|----------|-----------|-----------|-----------|\n",
        "|Time (s) |          |           |           |           |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMbHkDpk9K1G"
      },
      "source": [
        "How does the run time of dynamic vs static scheduling compare when the program is run with multiple threads?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr3A62lh9bl1"
      },
      "source": [
        "We are using Python to assisst us with the speed up calculation below. \n",
        "\n",
        "Try calculate the speed-up for each of the (thread number, scheduling) combination. Replace the `??` in the Python code below with numbers from your table. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ffmt44Sh9trQ"
      },
      "outputs": [],
      "source": [
        "#lists holding measured times (floating point)\n",
        "#TODO: Fill in arrays below (code will not compile otherwise!)\n",
        "#Time (n threads)  1   2  3  4\n",
        "dd_times =       [ ??, ??, ??, ??]\n",
        "\n",
        "#compute speedup\n",
        "speedup  = [round(dd_times[0]/dd_times[i],2)   for i in range(1,4)]\n",
        "\n",
        "#print results\n",
        "print(\"Speed-up:\")\n",
        "print(speedup)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9-P-_lC-DRJ"
      },
      "source": [
        "## Summary - Work Stealing Scheduling\n",
        "\n",
        "In many cases, parallel threads are scheduled using a static scheduling where it is assumed that all components take about the same amount of time. However, if some components take longer than others, a **load balancing** issue can arise. In the case of the drug design example, different ligands take longer to compute than others. Therefore, a work-stealing scheduling approach is better.\n",
        "\n",
        "Next, note that speedup is non-linear, especially at higher number of threads. While increasing the number of threads is supposed to generally _improve_ the run time of a program, it usually does not scale linearly with the number of cores. This occurs for a number of reasons. First, at higher number of threads, it is more likely that the serial components of a program (such as thread creation overhead, and any other necessary serial operations that must take place before the parallel code can run) start dominating run time (see **Amdahl’s Law**). Second, **resource contention** on the CPU or memory from other processes can cause slow downs. A related measure called **efficiency** measures how _well_ a program uses the cores assigned to it.\n",
        "\n",
        "Further Reading on Performance: [Dive into Systems, Chapter 14.4](https://diveintosystems.org/antora/diveintosystems/1.0/SharedMemory/performance.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Java Parallel Stream Patternlets Notebook",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}